{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "# Semantics and Pragmatics, KIK-LG103\n",
    "\n",
    "## Lab session 2, Part 2\n",
    "\n",
    "---\n",
    "\n",
    "<font color=\"red\">**This page contains interactive graphics. It only works properly if you change to the \"classic notebook\" user interface. Start by selecting *Launch Classic Notebook* from the *Help* menu. (If you already did this for Part 1, your are fine.)**</font>\n",
    "\n",
    "---\n",
    "\n",
    "In the second lecture of the course, the first step towards word embeddings was *semantic feature analysis*. In semantic feature analysis we try to find a minimal set of (often binary) features which we can use to discriminate between the meanings of the words. Let's start this session with the same idea. \n",
    "\n",
    "Again, remember to run the cell below to set a variable that controls how the figures are displayed and to import the library `plot_utils` for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import sys\n",
    "sys.path.append(\"../../../sem-prag-2025/src\")\n",
    "import plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1: Semantic feature analysis in three dimensions\n",
    "\n",
    "---\n",
    "\n",
    "In the code cell below you can see an example of semantic feature analysis (from slide 39 of Lecture 2).\n",
    "\n",
    "In `features` we find the names of the features we want to use, linked to their respective axes *x*, *y*, and *z*. The feature names are only used for visualization.\n",
    "\n",
    "Next we define a list of words with their analyses. Each word is represented as a pair of a word and its feature vector: `(word, feature_vector)`. The word is a string as always, and the feature vector is represented as a list of integer numbers (`[x, y, z]`). Our semantic features have three possible values, so let's use 1 for *positive*, -1 for *negative*, and 0 for *undefined*.\n",
    "\n",
    "The function `plot_3d_binary` plots the word vectors, and finally `tabulate_angles` shows the pairwise angles between the vectors in a table. \n",
    "\n",
    "Run the cell and inspect the output. Can you find any meaningful or interesting relations between the word vectors (that is, their angles)? For example, how do the two groups (cow, bull, calf) and (woman, man, child) relate to each other?\n",
    "\n",
    "**NOTE:** The figure should be dynamic; you should be able to rotate it etc. If it is static, run the cell above with the line `%matplotlib notebook` again. Then rerun the cell below and it should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"x\": \"human\",\n",
    "    \"y\": \"adult\",\n",
    "    \"z\": \"male\"\n",
    "}\n",
    "\n",
    "# Features are binary; 0 means 'not defined'\n",
    "words = [\n",
    "    (\"child\", [ 1, -1,  0]),\n",
    "    (\"girl\",  [ 1, -1, -1]),\n",
    "    (\"boy\",   [ 1, -1,  1]),\n",
    "    (\"adult\", [ 1,  1,  0]),\n",
    "    (\"woman\", [ 1,  1, -1]),\n",
    "    (\"man\",   [ 1,  1,  1]),\n",
    "    (\"calf\",  [-1, -1,  0]),\n",
    "    (\"bull\",  [-1,  1,  1]),\n",
    "    (\"cow\",   [-1,  1, -1])\n",
    "]\n",
    "\n",
    "plot_utils.plot_3d_binary(features, words)\n",
    "plot_utils.tabulate_angles(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Exercise 2.1.1** In the code cell below, first modify the example above by replacing the three words *calf*, *bull*, and *cow* with other words. Then come up with words for the two new added feature vectors.\n",
    "\n",
    "Have a look at the figure and rotate it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    \"x\": \"human\",\n",
    "    \"y\": \"adult\",\n",
    "    \"z\": \"male\"\n",
    "}\n",
    "\n",
    "# Features are binary; 0 means 'not defined'\n",
    "words = [\n",
    "    (\"child\", [ 1, -1,  0]),\n",
    "    (\"girl\",  [ 1, -1, -1]),\n",
    "    (\"boy\",   [ 1, -1,  1]),\n",
    "    (\"adult\", [ 1,  1,  0]),\n",
    "    (\"woman\", [ 1,  1, -1]),\n",
    "    (\"man\",   [ 1,  1,  1]),\n",
    "    (\"calf\",  [-1, -1,  0]),  # 1. replace calf with another noun that is not human, not adult, and unspecified gender\n",
    "    (\"bull\",  [-1,  1,  1]),  # 2. replace bull with another noun that is not human, but adult and male\n",
    "    (\"cow\",   [-1,  1, -1]),  # 3. replace cow with another noun that is not human, but adult and female\n",
    "    (\"?\",     [-1, -1, -1]),  # 4. come up with a noun that is not human, not adult, and not male\n",
    "    (\"??\",    [ 0,  1,  1])   # 5. come up with a noun that can be human or not human, and is adult, and male\n",
    "]\n",
    "\n",
    "plot_utils.plot_3d_binary(features, words)\n",
    "plot_utils.tabulate_angles(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2: Semantic feature analysis with more features\n",
    "\n",
    "---\n",
    "\n",
    "The restriction on the number of features to three is clearly too strict. In reality we need many more features to fully analyze even a small number of words. In this section we get rid of this limitation.\n",
    "\n",
    "Below you can see an example from the slides again (slide 40). In this case we have 7 features (*individual*, *team*, *indoors*, *outdoors*, *board game*, *card game*, *kid's game*). Consequently the embeddings (vectors) reside in a 7-dimensional vector space. \n",
    "\n",
    "As you might imagine, visualizing 7-dimensional vectors requires some extra work. In the slides we quickly heard about *dimensionality reduction*. In this example, we reduce the dimensionality of the data to 2 or 3 dimensions, so that we can plot it using conventional methods. It suffices to say here that the dimensionality reduction method we use is **Principal component analysis** (PCA). \n",
    "\n",
    "*If you are interested, you can read more about PCA [in this visual explanation](http://setosa.io/ev/principal-component-analysis/) or on [Wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis). This is completely optional and beyond the scope of this course. Especially the Wikipedia article requires substantial mathematical knowledge.*\n",
    "\n",
    "Because the dimensionality of the original vectors is high and we need to perform PCA on them, the resulting 2 or 3 dimensions do not necessarily correspond to any of our original features. Because of this, we cannot name the axes in the figures anymore, and so the function we use in this section doesn't require the `features` dictionary as an argument. \n",
    "\n",
    "The functions we use here are `plot_2d_binary_hd` and `plot_3d_binary_hd` (`hd` for high-dimensional). The `2d` function plots a 2D graph and the `3d` version plots a 3D graph like the one we saw above. In addition, you can control whether the vectors are plotted as dots or arrows using the boolean argument `arrows`.\n",
    "\n",
    "Again, run the code cell below and inspect the output. Does it make sense?\n",
    "\n",
    "**Note:** When you look at the angles between the vectors, they are actually angles in the original seven-dimensional space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: (1) individual, (2) team, (3) indoors, \n",
    "#           (4) outdoors, (5) board game,\n",
    "#           (6) card game, (7) kid's game\n",
    "\n",
    "words = [           #  (1) (2) (3) (4) (5) (6) (7)\n",
    "    (\"football\",      [-1,  1, -1,  1, -1, -1,  0]),\n",
    "    (\"marbles\",       [ 1, -1,  1,  1, -1, -1,  1]),\n",
    "    (\"tag\",           [ 1,  1, -1,  1, -1, -1,  1]),\n",
    "    (\"hide and seek\", [ 1,  1, -1,  1, -1, -1,  1]),\n",
    "    (\"scrabble\",      [ 1,  1,  1, -1,  1, -1,  0]),\n",
    "    (\"candyland\",     [ 1, -1,  1, -1,  1, -1,  1]),\n",
    "    (\"video games\",   [ 1,  0,  1, -1, -1, -1,  0]),\n",
    "    (\"hop scotch\",    [ 1,  1, -1,  1, -1, -1,  1]),\n",
    "    (\"checkers\",      [ 1,  0,  1, -1,  1, -1,  1]),\n",
    "    (\"golf\",          [ 1, -1, -1,  1, -1, -1,  1]),\n",
    "    (\"old maid\",      [ 1, -1,  1, -1, -1,  1,  1]),\n",
    "]\n",
    "\n",
    "plot_utils.plot_2d_binary_hd(words, arrows=False)\n",
    "plot_utils.plot_3d_binary_hd(words, arrows=True)\n",
    "plot_utils.tabulate_angles(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now done with Part 2. However, it is important to understand the high-dimensional _games_ vectors in Section 2.2 above, because one of the home assignments is very similar to this particular example.\n",
    "\n",
    "You can move on to Part 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
