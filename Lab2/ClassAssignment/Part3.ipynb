{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantics and Pragmatics, KIK-LG103\n",
    "\n",
    "## Lab session 2, Part 3\n",
    "\n",
    "---\n",
    "\n",
    "<font color=\"red\">**This page contains interactive graphics. It only works properly if you change to the \"classic notebook\" user interface. Start by selecting *Launch Classic Notebook* from the *Help* menu. (If you already did this for Part 1 or Part 2, your are fine.)**</font>\n",
    "\n",
    "---\n",
    "\n",
    "In Part 3 of this session we will move on from binary hand-crafted features to the current state of the art word embeddings. More specifically, the embeddings we will use are learned with one variant of a group of models often called **Word2Vec** (W2V). Unfortunately the model itself is again a bit too complicated for this course.\n",
    "\n",
    "In two sentences, the W2V model we use works by constructing an artificial task on a very large corpus of text. In the task we train a neural network to predict which words occur in the context of a given word, and magically, awesome word embeddings emerge. \n",
    "\n",
    "*The mathematically inclined can read more about Word2Vec for example [here](https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b).*\n",
    "\n",
    "As always, import the necessary library by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import sys\n",
    "sys.path.append(\"../../../sem-prag-2025/src\")\n",
    "import plot_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.1: Visualizing Word2Vec embeddings\n",
    "\n",
    "First let's retrieve the embeddings we want to use. `plot_utils` offers a convenient function `get_embeddings`, which returns the embeddings and a dictionary that we call `mappings`. Run the cell. The output and the variables `embeddings` and `mapping` are explained below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, mapping = plot_utils.get_embeddings()\n",
    "\n",
    "print(\"'embeddings' is a matrix with dimensions %s.\" % str(embeddings.shape))\n",
    "print(\"The number of vocabulary items is %d.\" % len(mapping))\n",
    "print(\"The dimensionality of the embeddings is %d.\" % embeddings.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embeddings are gathered in a matrix where each row corresponds to a vocabulary item and each column is a feature. Our matrix has dimensions `(25707, 300)`, that is, the number of words is 25707 and each word is represented as a 300-dimensional vector.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c c}\n",
    "\\textbf{rows are words} & \\textbf{columns are features}\\\\\n",
    "\\downarrow & \\downarrow \\\\\n",
    "  \\begin{array}{c c c}\n",
    "  you \\\\\n",
    "  dog \\\\\n",
    "  cat \\\\\n",
    "  ... \\\\\n",
    "  jump\n",
    "  \\end{array} \n",
    "&\n",
    "\\left[\n",
    "  \\begin{array}{c c c c}\n",
    "  0.1   & 0.001 & ... & 0.032 \\\\\n",
    "  0.23  & 0.062 & ... & 0.02 \\\\ \n",
    "  \\textbf{0.57}  & \\textbf{0.042} & ... & \\textbf{0.02} \\\\ \n",
    "        &       &     &      \\\\ \n",
    "  0.012 & 0.4   & ... & 0.091\n",
    "  \\end{array}\n",
    "\\right] \n",
    "& \\leftarrow \\textbf{This row is the vector for \"cat\"}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In contrast to the vectors in Part 2, the features (dimensions) in these vectors don't necessarily have a clear interpretation. We cannot always say that, for example, feature number 152 indicates 'adultness', or any other intuitive semantic feature. What matters is that similar words should have similar vectors.\n",
    "\n",
    "So what is the variable `mapping`? It is a mapping from words to their row indices in the embedding matrix. For example, the first row of the matrix `embeddings` is the vector for the word \"*you*\", so the value returned by `mapping[\"you\"]` is `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mapping[\"you\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the vector for \"*you*\" using the index we just got (which is 0 for *you*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prints out a 300-dimensional vector that can be annoyingly\n",
    "# large in the output cell. You can collapse the output by clicking\n",
    "# the left margin between the output and the colored bar on the left.\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Exercise 3.1.1** Now, it is your turn to retrieve the embedding vector for another word than *you*. Write code in the cell below that prints the embedding of the word *jump*.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First find out the mapping for \"jump\"\n",
    "\n",
    "# Then print the embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will again visualize the embeddings. In the code cell below we supply a list of words and illustrate the usage of two new functions `plot_w2v_2d` and `plot_w2v_3d` for plotting the W2V vectors. Notice that you need to supply the embeddings and the mapping dictionary in addition to the word list.\n",
    "\n",
    "Run the code cell below and inspect the output. Does it make any sense? (If the plots are not dynamic, rerun the cell at the top of this page, and then the cell below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = \"dog cat king queen man woman prince house car motorcycle pig horse cow\".split()\n",
    "\n",
    "plot_utils.plot_w2v_2d(\n",
    "    words=word_list,\n",
    "    embeddings=embeddings,\n",
    "    mapping=mapping,\n",
    "    arrows=True\n",
    ")\n",
    "\n",
    "plot_utils.plot_w2v_3d(\n",
    "    words=word_list,\n",
    "    embeddings=embeddings,\n",
    "    mapping=mapping,\n",
    "    arrows=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Exercise 3.1.2** In the code cell below, analyze and visualize the embeddings for some words of you choice. Try to see if you can find patters in the results: Which word pairs/groups seem to work well and which don't? \n",
    "\n",
    "Use a reasonable number of words (for example 6 or more).\n",
    "\n",
    "All words should be lowercase. If you use the `split` method as above, the words need to be separated by whitespace. You can try out visualizing in 2D and 3D, with and without arrows, depending on which style you like.\n",
    "\n",
    "If you can't see a word in the output, you might have chosen a word that is not in the vocabulary. The vocabulary contains a bit less than 26000 frequent English words.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_list = \"word1 word2\".split()\n",
    "\n",
    "plot_utils.plot_w2v_3d(\n",
    "    words=word_list,\n",
    "    embeddings=embeddings,\n",
    "    mapping=mapping,\n",
    "    arrows=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done studying word2vec embeddings, you can start working on the home assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
